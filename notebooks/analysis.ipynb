{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de4033-ad4b-4dc9-b64f-c7d7b6e39411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff26d51-5444-413f-b7e0-5816f7d1679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a0a9a-bc01-452d-b8bb-24ce1b4fde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "data_dir = '/home/jovyan/.cache/kagglehub/datasets/nandanp6/cataract-image-dataset/versions/3/processed_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee33617-de94-41dc-bfb0-cc622beac30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations with augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f1309-f0e3-48bb-8a88-e921ea9de8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "full_dataset = datasets.ImageFolder(os.path.join(data_dir,'train'), transform=transform_train)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# Update validation transform\n",
    "val_dataset.dataset.transform = transform_val\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95bc344-9465-4508-9cc8-3c72e49b8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Vanilla CNN\n",
    "def build_cnn():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 56 * 56, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "def get_pretrained_model(model_name):\n",
    "    if model_name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[6] = nn.Linear(4096, 1)\n",
    "    elif model_name == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.last_channel, 1)\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279cc005-20bd-48dd-ae18-01f22e6a4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10, patience=3):\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(loss=running_loss / (total_train // labels.size(0)))\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accuracies.append(correct_train / total_train)\n",
    "\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_loader, return_metrics=True)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430568c8-f58e-49ad-92c0-b8930b430afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, val_loader, return_metrics=False):\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    val_loss = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images).squeeze()\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    preds_binary = [1 if p > 0.5 else 0 for p in preds]\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = sum(p == t for p, t in zip(preds_binary, true_labels)) / len(true_labels)\n",
    "\n",
    "    if return_metrics:\n",
    "        return val_loss, accuracy\n",
    "\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, preds_binary))\n",
    "\n",
    "    cm = confusion_matrix(true_labels, preds_binary)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    auc = roc_auc_score(true_labels, preds)\n",
    "    print(f\"AUC Score: {auc:.4f}\")\n",
    "\n",
    "    RocCurveDisplay.from_predictions(true_labels, preds)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3ac45-1e7e-460b-9b8f-16a87f1e7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate and train\n",
    "model_choice = \"mobilenetv2\"  # Choose \"cnn\", \"vgg16\", or \"mobilenetv2\"\n",
    "if model_choice == \"cnn\":\n",
    "    model = build_cnn().to(device)\n",
    "elif model_choice in [\"vgg16\", \"mobilenetv2\"]:\n",
    "    model = get_pretrained_model(model_choice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42caf4e5-c7da-4910-9fc0-f8bfddf1f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76903a3a-aa18-461b-b846-ee1434345029",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d0d12-1ae7-4c2c-b363-3a7fd07328e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder(os.path.join(data_dir,'test'),transform = transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d473005-e33b-4de7-84f3-17752ecbeb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fefe6-a014-44cb-a482-87a24d9ea009",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_loader)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
